{"cells":[{"cell_type":"code","execution_count":1,"id":"581d5e5b","metadata":{"id":"581d5e5b"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.12/site-packages/openface-0.3.2-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: jax in /opt/anaconda3/lib/python3.12/site-packages (0.5.2)\n","Requirement already satisfied: jaxlib<=0.5.2,>=0.5.1 in /opt/anaconda3/lib/python3.12/site-packages (from jax) (0.5.1)\n","Requirement already satisfied: ml_dtypes>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from jax) (0.4.1)\n","Requirement already satisfied: numpy>=1.25 in /opt/anaconda3/lib/python3.12/site-packages (from jax) (1.26.4)\n","Requirement already satisfied: opt_einsum in /opt/anaconda3/lib/python3.12/site-packages (from jax) (3.4.0)\n","Requirement already satisfied: scipy>=1.11.1 in /opt/anaconda3/lib/python3.12/site-packages (from jax) (1.13.1)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install jax"]},{"cell_type":"code","execution_count":2,"id":"f02d92e3","metadata":{},"outputs":[],"source":["import jax.numpy as jnp\n","from jax import grad, jit, vmap\n","from jax import random"]},{"cell_type":"code","execution_count":3,"id":"368bd673","metadata":{"id":"368bd673"},"outputs":[],"source":["# A helper function to randomly initialize weights and biases\n","# for a dense neural network layer\n","def random_layer_params(m, n, key, scale=1e-2):\n","  w_key, b_key = random.split(key)\n","  return scale * random.normal(w_key, (n, m)), scale * random.normal(b_key, (n,))\n","\n","# Initialize all layers for a fully-connected neural network with sizes \"sizes\"\n","def init_network_params(sizes, key):\n","  keys = random.split(key, len(sizes))\n","  return [random_layer_params(m, n, k) for m, n, k in zip(sizes[:-1], sizes[1:], keys)]\n","\n","layer_sizes = [784, 512, 512, 10]\n","step_size = 0.01\n","num_epochs = 10\n","batch_size = 128\n","n_targets = 10\n","params = init_network_params(layer_sizes, random.PRNGKey(0))"]},{"cell_type":"code","execution_count":4,"id":"94bad908","metadata":{"id":"94bad908"},"outputs":[],"source":["from jax.scipy.special import logsumexp\n","\n","def relu(x):\n","    return jnp.maximum(0, x)\n","\n","def predict(params, image):\n","  # per-example predictions\n","  activations = image\n","  for w, b in params[:-1]:\n","    outputs = jnp.dot(w, activations) + b\n","    activations = relu(outputs)\n","\n","  final_w, final_b = params[-1]\n","  logits = jnp.dot(final_w, activations) + final_b\n","  return logits - logsumexp(logits)"]},{"cell_type":"code","execution_count":5,"id":"4183285d","metadata":{"id":"4183285d","outputId":"ac47a432-782a-484c-cf2f-549d337cbf75"},"outputs":[{"name":"stdout","output_type":"stream","text":["(10,)\n"]}],"source":["# This works on single examples\n","random_flattened_image = random.normal(random.PRNGKey(1), (28 * 28,))\n","preds = predict(params, random_flattened_image)\n","print(preds.shape)"]},{"cell_type":"code","execution_count":6,"id":"a75ba04c","metadata":{"id":"a75ba04c","outputId":"e3910255-c7e8-4cb2-a95b-81656c1d9c85"},"outputs":[{"name":"stdout","output_type":"stream","text":["Invalid shapes!\n"]}],"source":["# Doesn't work with a batch\n","random_flattened_images = random.normal(random.PRNGKey(1), (10, 28 * 28))\n","try:\n","  preds = predict(params, random_flattened_images)\n","except TypeError:\n","  print('Invalid shapes!')"]},{"cell_type":"code","execution_count":7,"id":"e68632c5","metadata":{"id":"e68632c5","outputId":"d102041f-11d0-4209-8351-3d57566ba1c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["(10, 10)\n"]}],"source":["# Let's upgrade it to handle batches using `vmap`\n","\n","# Make a batched version of the `predict` function\n","batched_predict = vmap(predict, in_axes=(None, 0))\n","\n","# `batched_predict` has the same call signature as `predict`\n","batched_preds = batched_predict(params, random_flattened_images)\n","print(batched_preds.shape)"]},{"cell_type":"code","execution_count":8,"id":"ebfb97dd","metadata":{"id":"ebfb97dd"},"outputs":[],"source":["def one_hot(x, k, dtype=jnp.float32):\n","  \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n","  return jnp.array(x[:, None] == jnp.arange(k), dtype)\n","\n","def accuracy(params, images, targets):\n","  target_class = jnp.argmax(targets, axis=1)\n","  predicted_class = jnp.argmax(batched_predict(params, images), axis=1)\n","  return jnp.mean(predicted_class == target_class)\n","\n","def loss(params, images, targets):\n","  preds = batched_predict(params, images)\n","  return -jnp.mean(preds * targets)\n","\n","@jit\n","def update(params, x, y):\n","  grads = grad(loss)(params, x, y)\n","  return [(w - step_size * dw, b - step_size * db)\n","          for (w, b), (dw, db) in zip(params, grads)]"]},{"cell_type":"code","execution_count":9,"id":"f48776f0","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MNIST dataset successfully downloaded and processed.\n"]}],"source":["import os\n","import gzip\n","import shutil\n","import numpy as np\n","import urllib.request\n","from urllib.error import URLError\n","from zipfile import ZipFile\n","from io import BytesIO\n","# URL for the MNIST dataset ZIP file\n","MNIST_ZIP_URL = 'https://data.deepai.org/mnist.zip'\n","def download_and_extract_mnist_zip(url, dest_folder):\n","    \"\"\"Download and extract the MNIST ZIP file.\"\"\"\n","    if not os.path.exists(dest_folder):\n","        os.makedirs(dest_folder)\n","    zip_path = os.path.join(dest_folder, 'mnist.zip')\n","    try:\n","        urllib.request.urlretrieve(url, zip_path)\n","    except URLError as e:\n","        print(f\"Failed to download the dataset. Error: {e}\")\n","        return False\n","    with ZipFile(zip_path, 'r') as zip_ref:\n","        zip_ref.extractall(dest_folder)\n","    os.remove(zip_path)\n","    return True\n","def extract_gz_file(gz_path, dest_path):\n","    \"\"\"Extract a .gz file.\"\"\"\n","    with gzip.open(gz_path, 'rb') as f_in:\n","        with open(dest_path, 'wb') as f_out:\n","            shutil.copyfileobj(f_in, f_out)\n","def load_mnist_images(file_path):\n","    \"\"\"Load MNIST images from the IDX file format.\"\"\"\n","    with open(file_path, 'rb') as f:\n","        data = np.frombuffer(f.read(), np.uint8, offset=16)\n","    return data.reshape(-1, 784)\n","def load_mnist_labels(file_path):\n","    \"\"\"Load MNIST labels from the IDX file format.\"\"\"\n","    with open(file_path, 'rb') as f:\n","        data = np.frombuffer(f.read(), np.uint8, offset=8)\n","    return data\n","# Define paths\n","data_folder = '/tmp/mnist_data'\n","train_images_path = os.path.join(data_folder, 'train-images-idx3-ubyte')\n","train_labels_path = os.path.join(data_folder, 'train-labels-idx1-ubyte')\n","test_images_path = os.path.join(data_folder, 't10k-images-idx3-ubyte')\n","test_labels_path = os.path.join(data_folder, 't10k-labels-idx1-ubyte')\n","# Download and extract the MNIST dataset\n","if download_and_extract_mnist_zip(MNIST_ZIP_URL, data_folder):\n","    # Extract .gz files\n","    extract_gz_file(train_images_path + '.gz', train_images_path)\n","    extract_gz_file(train_labels_path + '.gz', train_labels_path)\n","    extract_gz_file(test_images_path + '.gz', test_images_path)\n","    extract_gz_file(test_labels_path + '.gz', test_labels_path)\n","    # Load data\n","    train_images = load_mnist_images(train_images_path)\n","    train_labels = load_mnist_labels(train_labels_path)\n","    test_images = load_mnist_images(test_images_path)\n","    test_labels = load_mnist_labels(test_labels_path)\n","    # One-hot encoding of labels\n","    def one_hot(labels, num_classes):\n","        return np.eye(num_classes)[labels]\n","    num_labels = 10  # MNIST has 10 classes\n","    train_labels = one_hot(train_labels, num_labels)\n","    test_labels = one_hot(test_labels, num_labels)\n","    print(\"MNIST dataset successfully downloaded and processed.\")\n","else:\n","    print(\"Failed to download and process the MNIST dataset.\")\n","\n"]},{"cell_type":"code","execution_count":10,"id":"4c300902","metadata":{"id":"4c300902","outputId":"76e3e62d-a8bf-4fe4-8d20-2568539a663f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train: (60000, 784) (60000, 10)\n","Test: (10000, 784) (10000, 10)\n"]}],"source":["print('Train:', train_images.shape, train_labels.shape)\n","print('Test:', test_images.shape, test_labels.shape)"]},{"cell_type":"code","execution_count":11,"id":"74aa3ea9","metadata":{"id":"74aa3ea9","outputId":"a373ff69-2b3b-409a-b579-d32b5572cc44"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0 in 1.15 sec\n","Training set accuracy 0.9200000166893005\n","Test set accuracy 0.9205999970436096\n","Epoch 1 in 0.80 sec\n","Training set accuracy 0.9403166770935059\n","Test set accuracy 0.9414999485015869\n","Epoch 2 in 0.80 sec\n","Training set accuracy 0.9512166976928711\n","Test set accuracy 0.9483000040054321\n","Epoch 3 in 0.83 sec\n","Training set accuracy 0.9586333632469177\n","Test set accuracy 0.9544999599456787\n","Epoch 4 in 0.91 sec\n","Training set accuracy 0.9646833539009094\n","Test set accuracy 0.9587999582290649\n","Epoch 5 in 0.97 sec\n","Training set accuracy 0.9686999917030334\n","Test set accuracy 0.962399959564209\n","Epoch 6 in 1.04 sec\n","Training set accuracy 0.9713166952133179\n","Test set accuracy 0.9645999670028687\n","Epoch 7 in 0.85 sec\n","Training set accuracy 0.9758000373840332\n","Test set accuracy 0.9674999713897705\n","Epoch 8 in 0.89 sec\n","Training set accuracy 0.9776666760444641\n","Test set accuracy 0.9687999486923218\n","Epoch 9 in 0.89 sec\n","Training set accuracy 0.9776000380516052\n","Test set accuracy 0.9677000045776367\n"]}],"source":["import time\n","import numpy as np\n","\n","def get_train_batches(batch_size):\n","    \"\"\"Yield batches of train data.\"\"\"\n","    num_samples = train_images.shape[0]\n","    indices = np.arange(num_samples)\n","    np.random.shuffle(indices)  # shuffle the indices for randomness\n","\n","    for start_idx in range(0, num_samples, batch_size):\n","        end_idx = min(start_idx + batch_size, num_samples)\n","        batch_indices = indices[start_idx:end_idx]\n","        yield train_images[batch_indices], train_labels[batch_indices]\n","\n","# Assuming you have defined num_epochs, batch_size, and update functions\n","for epoch in range(num_epochs):\n","    start_time = time.time()\n","    for x, y in get_train_batches(batch_size):\n","        x = x.reshape(len(x), -1)  # Flatten the images if not already\n","        params = update(params, x, y)\n","    epoch_time = time.time() - start_time\n","\n","    train_acc = accuracy(params, train_images.reshape(len(train_images), -1), train_labels)\n","    test_acc = accuracy(params, test_images.reshape(len(test_images), -1), test_labels)\n","    print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n","    print(\"Training set accuracy {}\".format(train_acc))\n","    print(\"Test set accuracy {}\".format(test_acc))\n"]},{"cell_type":"code","execution_count":12,"id":"8ab3bd86","metadata":{"id":"8ab3bd86","outputId":"230340cd-f6b8-4f6c-feba-a4c4fdf29cca"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x200 with 5 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Placeholder for the model's predict function\n","# Replace this with your actual model's prediction method\n","\n","# Select five random test images\n","num_samples = 5\n","indices = np.random.choice(len(test_images), num_samples, replace=False)\n","selected_images = test_images[indices]\n","selected_labels = test_labels[indices]\n","\n","# Generate predictions\n","# Replace 'model' with your actual model\n","predicted_labels = np.argmax(batched_predict(params, selected_images),axis=1)\n","\n","# Visualize the images and the predictions\n","plt.figure(figsize=(10, 2))\n","for i, (image, label) in enumerate(zip(selected_images, predicted_labels)):\n","    plt.subplot(1, num_samples, i + 1)\n","    plt.imshow(image.reshape(28, 28), cmap='gray')\n","    plt.title(f'Predicted: {label}')\n","    plt.axis('off')\n","plt.show()\n"]},{"cell_type":"markdown","id":"28e0797b","metadata":{"id":"28e0797b"},"source":["## Next draw your own digits!"]},{"cell_type":"code","execution_count":14,"id":"4d6d5dd4","metadata":{},"outputs":[],"source":["import tkinter as tk\n","from tkinter import Canvas\n","import numpy as np\n","from PIL import Image, ImageDraw"]},{"cell_type":"code","execution_count":16,"id":"96814c81","metadata":{"id":"96814c81"},"outputs":[],"source":["import tkinter as tk\n","from tkinter import Canvas\n","import numpy as np\n","from PIL import Image, ImageDraw\n","\n","\n","# Function to draw on the canvas\n","def draw(event):\n","    x, y = event.x, event.y\n","    canvas.create_oval((x, y, x + 10, y + 10), fill='black')\n","    draw_image.line([x, y, x + 1, y + 1], fill='black', width=10)\n","\n","# Function to predict the digit\n","# def predict_digit():\n","#     canvas.postscript(file='digit.eps', colormode='color')\n","#     img = Image.open('digit.eps')\n","#     if img.mode not in [\"RGB\", \"L\"]:\n","#         img = img.convert(\"RGB\")    \n","#     img = img.resize((28, 28), Image.Resampling.LANCZOS).convert('L')\n","#     img = np.array(img)\n","#     img = 1-img / 255.0\n","\n","#     digit = np.argmax(predict(params,np.ndarray.flatten(img)))\n","#     label.config(text=str(digit))\n","import tkinter as tk\n","from tkinter import Canvas\n","import numpy as np\n","from PIL import Image, ImageDraw\n","\n","# Function to predict the digit\n","def predict_digit():\n","    # Save the canvas drawing as an EPS file\n","    canvas.postscript(file='digit.eps', colormode='color')\n","    \n","    # Open EPS and save as PNG to avoid mode issues\n","    img = Image.open('digit.eps')\n","    img.save('digit.png', 'PNG')  # Convert to PNG first\n","    img = Image.open('digit.png')  # Reopen as PNG\n","\n","    # Ensure correct mode before processing\n","    if img.mode not in [\"RGB\", \"L\"]:\n","        img = img.convert(\"RGB\")\n","\n","    # Resize and convert to grayscale ('L' mode)\n","    img = img.resize((28, 28), Image.LANCZOS).convert('L')\n","\n","    # Convert to numpy array and normalize\n","    img = np.array(img)\n","    img = 1 - img / 255.0  # Normalize pixel values\n","\n","    # Predict the digit\n","    digit = np.argmax(predict(params, np.ndarray.flatten(img)))\n","    label.config(text=str(digit))\n","\n","\n","# Function to clear the canvas and the image\n","def clear_canvas():\n","    canvas.delete(\"all\")\n","    draw_image.rectangle((0, 0, 150, 150), fill='white')\n","    label.config(text=\"Draw a digit\")\n","\n","# Create the main window\n","root = tk.Tk()\n","root.title(\"Digit Predictor\")\n","\n","# Create a drawing canvas\n","canvas = Canvas(root, width=150, height=150, bg='white')\n","canvas.pack()\n","\n","# PIL Image and Draw for capturing the drawn digit\n","image = Image.new(\"RGB\", (150, 150), 'white')\n","draw_image = ImageDraw.Draw(image)\n","\n","# Bind the drawing function to mouse drag\n","canvas.bind(\"<B1-Motion>\", draw)\n","\n","# Add a button to predict the digit\n","button_predict = tk.Button(root, text=\"Predict\", command=predict_digit)\n","button_predict.pack()\n","\n","# Add a button to clear the canvas\n","button_clear = tk.Button(root, text=\"Clear\", command=clear_canvas)\n","button_clear.pack()\n","\n","# Label to display the prediction\n","label = tk.Label(root, text=\"Draw a digit\", font=(\"Helvetica\", 16))\n","label.pack()\n","\n","# Run the application\n","root.mainloop()"]},{"cell_type":"markdown","id":"j5JKbYa2bk0Y","metadata":{"id":"j5JKbYa2bk0Y"},"source":["1. (1 point) How many layers are there in the neural network?\n","2. (1 point) What are the shapes of each parameter in \"params\"?\n","3. (2 points) Which activation function is used?\n","4. (2 points) What are the input space and label space?\n","5. (2 points) What does ``predict'' output?\n","6. (2 points) What are the training accuracy and test accuracy after 10 epochs? Use the GUI, write your 1,2,3,4,...,10 using your mouse.  Write a short report that shows your digits and the classification results.\n","7. (2 points) What is the classification accuracy on your data?  Is it better or worse than the accuracy on the test set?   If it is very different, could you explain why?  Any ideas to fix the issue?"]},{"cell_type":"markdown","id":"_wJdH2pebiNt","metadata":{"id":"_wJdH2pebiNt"},"source":["# Discussion"]},{"cell_type":"code","execution_count":null,"id":"368619b2","metadata":{"id":"368619b2"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"}},"nbformat":4,"nbformat_minor":5}
